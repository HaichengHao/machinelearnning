<!DOCTYPE HTML>
<html lang="zh-hans" >
    
    <head>
        
        <meta charset="UTF-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <title>XGBoost-OTTO案例 | 传智播客-人工智能学院</title>
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="generator" content="GitBook 2.6.7">
        <meta name="author" content="Edward Meng">
        
        <meta name="HandheldFriendly" content="true"/>
        <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
        <meta name="apple-mobile-web-app-capable" content="yes">
        <meta name="apple-mobile-web-app-status-bar-style" content="black">
        <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../gitbook/images/apple-touch-icon-precomposed-152.png">
        <link rel="shortcut icon" href="../gitbook/images/favicon.ico" type="image/x-icon">
        
    <link rel="stylesheet" href="../gitbook/style.css">
    
        
        <link rel="stylesheet" href="../gitbook/plugins/gitbook-plugin-code/plugin.css">
        
    
        
        <link rel="stylesheet" href="../gitbook/plugins/gitbook-plugin-splitter/splitter.css">
        
    
        
        <link rel="stylesheet" href="../gitbook/plugins/gitbook-plugin-expandable-chapters/expandable-chapters.css">
        
    
        
        <link rel="stylesheet" href="../gitbook/plugins/gitbook-plugin-katex/katex.min.css">
        
    
        
        <link rel="stylesheet" href="../gitbook/plugins/gitbook-plugin-highlight/website.css">
        
    
        
        <link rel="stylesheet" href="../gitbook/plugins/gitbook-plugin-fontsettings/website.css">
        
    
    
        <link rel="stylesheet" href="../custom_style.css">
    

        
    
    
    <link rel="next" href="../05-集成学习进阶/section5.html" />
    
    
    <link rel="prev" href="../05-集成学习进阶/section3.html" />
    

        
    </head>
    <body>
        
        
    <div class="book"
        data-level="5.4"
        data-chapter-title="XGBoost-OTTO案例"
        data-filepath="05-集成学习进阶/section4.md"
        data-basepath=".."
        data-revision="Thu Aug 12 2021 20:16:16 GMT+0800 (CST)"
        data-innerlanguage="">
    

<div class="book-summary">
    <nav role="navigation">
        <ul class="summary">
            
            
            
                
                <li>
                    <a href="http://www.itheima.com/" target="blank" class="custom-link">黑马程序员</a>
                </li>
            
            

            
            <li class="divider"></li>
            

            
    
        <li class="chapter " data-level="0" data-path="index.html">
            
                
                    <a href="../index.html">
                
                        <i class="fa fa-check"></i>
                        
                        机器学习（算法篇2）
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1" data-path="01-朴素贝叶斯/index.html">
            
                
                    <a href="../01-朴素贝叶斯/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.</b>
                        
                        朴素贝叶斯
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.1" data-path="01-朴素贝叶斯/section1.html">
            
                
                    <a href="../01-朴素贝叶斯/section1.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.1.</b>
                        
                        朴素贝叶斯算法简介
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.2" data-path="01-朴素贝叶斯/section2.html">
            
                
                    <a href="../01-朴素贝叶斯/section2.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.2.</b>
                        
                        概率基础复习
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.3" data-path="01-朴素贝叶斯/section3.html">
            
                
                    <a href="../01-朴素贝叶斯/section3.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.3.</b>
                        
                        案例：商品评论情感分析
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.4" data-path="01-朴素贝叶斯/section4.html">
            
                
                    <a href="../01-朴素贝叶斯/section4.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.4.</b>
                        
                        朴素贝叶斯算法总结
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="2" data-path="02-支持向量机/index.html">
            
                
                    <a href="../02-支持向量机/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.</b>
                        
                        支持向量机
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="2.1" data-path="02-支持向量机/section1.html">
            
                
                    <a href="../02-支持向量机/section1.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.1.</b>
                        
                        SVM算法简介
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.2" data-path="02-支持向量机/section2.html">
            
                
                    <a href="../02-支持向量机/section2.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.2.</b>
                        
                        SVM算法api初步使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.3" data-path="02-支持向量机/section3.html">
            
                
                    <a href="../02-支持向量机/section3.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.3.</b>
                        
                        SVM算法原理
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.4" data-path="02-支持向量机/section4.html">
            
                
                    <a href="../02-支持向量机/section4.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.4.</b>
                        
                        SVM的损失函数
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.5" data-path="02-支持向量机/section5.html">
            
                
                    <a href="../02-支持向量机/section5.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.5.</b>
                        
                        SVM的核方法
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.6" data-path="02-支持向量机/section6.html">
            
                
                    <a href="../02-支持向量机/section6.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.6.</b>
                        
                        SVM回归
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.7" data-path="02-支持向量机/section7.html">
            
                
                    <a href="../02-支持向量机/section7.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.7.</b>
                        
                        SVM算法api再介绍
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.8" data-path="02-支持向量机/section8.html">
            
                
                    <a href="../02-支持向量机/section8.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.8.</b>
                        
                        案例：数字识别器
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.9" data-path="02-支持向量机/section9.html">
            
                
                    <a href="../02-支持向量机/section9.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.9.</b>
                        
                        SVM总结
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="3" data-path="03-EM算法/index.html">
            
                
                    <a href="../03-EM算法/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.</b>
                        
                        EM算法
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="3.1" data-path="03-EM算法/section1.html">
            
                
                    <a href="../03-EM算法/section1.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.1.</b>
                        
                        初识EM算法
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.2" data-path="03-EM算法/section2.html">
            
                
                    <a href="../03-EM算法/section2.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.2.</b>
                        
                        EM算法介绍
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.3" data-path="03-EM算法/section3.html">
            
                
                    <a href="../03-EM算法/section3.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.3.</b>
                        
                        EM算法实例
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="4" data-path="04-HMM模型/index.html">
            
                
                    <a href="../04-HMM模型/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.</b>
                        
                        HMM模型
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="4.1" data-path="04-HMM模型/section1.html">
            
                
                    <a href="../04-HMM模型/section1.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.1.</b>
                        
                        马尔科夫链
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="4.2" data-path="04-HMM模型/section2.html">
            
                
                    <a href="../04-HMM模型/section2.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.2.</b>
                        
                        HMM简介
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="4.3" data-path="04-HMM模型/section3.html">
            
                
                    <a href="../04-HMM模型/section3.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.3.</b>
                        
                        HMM模型基础
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="4.4" data-path="04-HMM模型/section4.html">
            
                
                    <a href="../04-HMM模型/section4.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.4.</b>
                        
                        前向后向算法评估观察序列概率
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="4.5" data-path="04-HMM模型/section5.html">
            
                
                    <a href="../04-HMM模型/section5.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.5.</b>
                        
                        维特比算法解码隐藏状态
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="4.6" data-path="04-HMM模型/section6.html">
            
                
                    <a href="../04-HMM模型/section6.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.6.</b>
                        
                        鲍姆-韦尔奇算法简介
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="4.7" data-path="04-HMM模型/section7.html">
            
                
                    <a href="../04-HMM模型/section7.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.7.</b>
                        
                        HMM模型api介绍
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="5" data-path="05-集成学习进阶/index.html">
            
                
                    <a href="../05-集成学习进阶/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>5.</b>
                        
                        集成学习进阶
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="5.1" data-path="05-集成学习进阶/section1.html">
            
                
                    <a href="../05-集成学习进阶/section1.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>5.1.</b>
                        
                        XGBoost算法原理
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="5.2" data-path="05-集成学习进阶/section2.html">
            
                
                    <a href="../05-集成学习进阶/section2.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>5.2.</b>
                        
                        XGBoost算法api介绍
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="5.3" data-path="05-集成学习进阶/section3.html">
            
                
                    <a href="../05-集成学习进阶/section3.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>5.3.</b>
                        
                        XGBoost案例介绍
                    </a>
            
            
        </li>
    
        <li class="chapter active" data-level="5.4" data-path="05-集成学习进阶/section4.html">
            
                
                    <a href="../05-集成学习进阶/section4.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>5.4.</b>
                        
                        XGBoost-OTTO案例
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="5.5" data-path="05-集成学习进阶/section5.html">
            
                
                    <a href="../05-集成学习进阶/section5.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>5.5.</b>
                        
                        LightGBM
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="5.6" data-path="05-集成学习进阶/section6.html">
            
                
                    <a href="../05-集成学习进阶/section6.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>5.6.</b>
                        
                        LightGBM算法api介绍
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="5.7" data-path="05-集成学习进阶/section7.html">
            
                
                    <a href="../05-集成学习进阶/section7.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>5.7.</b>
                        
                        LightGBM案例介绍
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="5.8" data-path="05-集成学习进阶/section8.html">
            
                
                    <a href="../05-集成学习进阶/section8.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>5.8.</b>
                        
                        案例：《绝地求生》玩家排名预测
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="6" data-path="06-拓展知识/index.html">
            
                
                    <a href="../06-拓展知识/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>6.</b>
                        
                        拓展知识
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="6.1" data-path="06-拓展知识/section1.html">
            
                
                    <a href="../06-拓展知识/section1.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>6.1.</b>
                        
                        向量与矩阵的范数
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="6.2" data-path="06-拓展知识/section2.html">
            
                
                    <a href="../06-拓展知识/section2.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>6.2.</b>
                        
                        拉格朗日乘子法
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="6.3" data-path="06-拓展知识/section3.html">
            
                
                    <a href="../06-拓展知识/section3.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>6.3.</b>
                        
                        极大似然函数取对数原因
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    


            
            <li class="divider"></li>
            <li>
                <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
                    本书使用 GitBook 发布
                </a>
            </li>
            
        </ul>
    </nav>
</div>

    <div class="book-body">
        <div class="body-inner">
            <div class="book-header" role="navigation">
    <!-- Actions Left -->
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href="../" >传智播客-人工智能学院</a>
    </h1>
</div>

            <div class="page-wrapper" tabindex="-1" role="main">
                <div class="page-inner">
                
                
                    <section class="normal" id="section-">
                    
                        <h1 id="114-otto&#x6848;&#x4F8B;&#x4ECB;&#x7ECD;--otto-group-product-classification-challenge&#x3010;xgboost&#x5B9E;&#x73B0;&#x3011;">11.4 otto&#x6848;&#x4F8B;&#x4ECB;&#x7ECD; -- Otto Group Product Classification Challenge&#x3010;xgboost&#x5B9E;&#x73B0;&#x3011;</h1>
<h2 id="1-&#x80CC;&#x666F;&#x4ECB;&#x7ECD;">1 &#x80CC;&#x666F;&#x4ECB;&#x7ECD;</h2>
<p>&#x5965;&#x6258;&#x96C6;&#x56E2;&#x662F;&#x4E16;&#x754C;&#x4E0A;&#x6700;&#x5927;&#x7684;&#x7535;&#x5B50;&#x5546;&#x52A1;&#x516C;&#x53F8;&#x4E4B;&#x4E00;&#xFF0C;&#x5728;20&#x591A;&#x4E2A;&#x56FD;&#x5BB6;&#x8BBE;&#x6709;&#x5B50;&#x516C;&#x53F8;&#x3002;&#x8BE5;&#x516C;&#x53F8;&#x6BCF;&#x5929;&#x90FD;&#x5728;&#x4E16;&#x754C;&#x5404;&#x5730;&#x9500;&#x552E;&#x6570;&#x767E;&#x4E07;&#x79CD;&#x4EA7;&#x54C1;,&#x6240;&#x4EE5;&#x5BF9;&#x5176;&#x4EA7;&#x54C1;&#x6839;&#x636E;&#x6027;&#x80FD;&#x5408;&#x7406;&#x7684;&#x5206;&#x7C7B;&#x975E;&#x5E38;&#x91CD;&#x8981;&#x3002;</p>
<p>&#x4E0D;&#x8FC7;,&#x5728;&#x5B9E;&#x9645;&#x5DE5;&#x4F5C;&#x4E2D;,&#x5DE5;&#x4F5C;&#x4EBA;&#x5458;&#x53D1;&#x73B0;,&#x8BB8;&#x591A;&#x76F8;&#x540C;&#x7684;&#x4EA7;&#x54C1;&#x5F97;&#x5230;&#x4E86;&#x4E0D;&#x540C;&#x7684;&#x5206;&#x7C7B;&#x3002;&#x672C;&#x6848;&#x4F8B;&#x8981;&#x6C42;,&#x4F60;&#x5BF9;&#x5965;&#x62D3;&#x96C6;&#x56E2;&#x7684;&#x4EA7;&#x54C1;&#x8FDB;&#x884C;&#x6B63;&#x786E;&#x7684;&#x5206;&#x5206;&#x7C7B;&#x3002;&#x5C3D;&#x53EF;&#x80FD;&#x7684;&#x63D0;&#x4F9B;&#x5206;&#x7C7B;&#x7684;&#x51C6;&#x786E;&#x6027;&#x3002;</p>
<p>&#x94FE;&#x63A5;&#xFF1A;<a href="https://www.kaggle.com/c/otto-group-product-classification-challenge/overview" target="_blank">https://www.kaggle.com/c/otto-group-product-classification-challenge/overview</a></p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g9cx5y8zhqj30i40dw3zf.jpg" alt="2nd iteration"></p>
<hr>
<h2 id="2-&#x601D;&#x8DEF;&#x5206;&#x6790;">2 &#x601D;&#x8DEF;&#x5206;&#x6790;</h2>
<ul>
<li><p>1.&#x6570;&#x636E;&#x83B7;&#x53D6;</p>
</li>
<li><p>2.&#x6570;&#x636E;&#x57FA;&#x672C;&#x5904;&#x7406;</p>
<ul>
<li>2.1 &#x622A;&#x53D6;&#x90E8;&#x5206;&#x6570;&#x636E;</li>
<li>2.2 &#x628A;&#x6807;&#x7B7E;&#x7EB8;&#x8F6C;&#x6362;&#x4E3A;&#x6570;&#x5B57;</li>
<li><strong>2.3 &#x5206;&#x5272;&#x6570;&#x636E;(&#x4F7F;&#x7528;StratifiedShuffleSplit)</strong></li>
<li><strong>2.4 &#x6570;&#x636E;&#x6807;&#x51C6;&#x5316;</strong></li>
<li><strong>2.5 &#x6570;&#x636E;pca&#x964D;&#x7EF4;</strong></li>
</ul>
</li>
<li><p><strong>3.&#x6A21;&#x578B;&#x8BAD;&#x7EC3;</strong></p>
<ul>
<li><strong>3.1 &#x57FA;&#x672C;&#x6A21;&#x578B;&#x8BAD;&#x7EC3;</strong></li>
<li><strong>3.2 &#x6A21;&#x578B;&#x8C03;&#x4F18;</strong><ul>
<li><strong>3.2.1 &#x8C03;&#x4F18;&#x53C2;&#x6570;:</strong><ul>
<li><strong>n_estimator,</strong> </li>
<li><strong>max_depth,</strong> </li>
<li><strong>min_child_weights,</strong> </li>
<li><strong>subsamples,</strong> </li>
<li><strong>consample_bytrees,</strong> </li>
<li><strong>etas</strong></li>
</ul>
</li>
<li><strong>3.2.2 &#x786E;&#x5B9A;&#x6700;&#x540E;&#x6700;&#x4F18;&#x53C2;&#x6570;</strong></li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="3-&#x90E8;&#x5206;&#x4EE3;&#x7801;&#x5B9E;&#x73B0;">3 &#x90E8;&#x5206;&#x4EE3;&#x7801;&#x5B9E;&#x73B0;</h2>
<ul>
<li>2.&#x6570;&#x636E;&#x57FA;&#x672C;&#x5904;&#x7406;</li>
<li>2.1 &#x622A;&#x53D6;&#x90E8;&#x5206;&#x6570;&#x636E;</li>
<li>2.2 &#x628A;&#x6807;&#x7B7E;&#x503C;&#x8F6C;&#x6362;&#x4E3A;&#x6570;&#x5B57;</li>
<li><strong>2.3 &#x5206;&#x5272;&#x6570;&#x636E;(&#x4F7F;&#x7528;StratifiedShuffleSplit)</strong></li>
</ul>
<pre><code class="lang-python"><span class="hljs-comment"># &#x4F7F;&#x7528;StratifiedShuffleSplit&#x5BF9;&#x6570;&#x636E;&#x96C6;&#x8FDB;&#x884C;&#x5206;&#x5272;</span>
<span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> StratifiedShuffleSplit

sss = StratifiedShuffleSplit(n_splits=<span class="hljs-number">1</span>, test_size=<span class="hljs-number">0.2</span>, random_state=<span class="hljs-number">0</span>)
<span class="hljs-keyword">for</span> train_index, test_index <span class="hljs-keyword">in</span> sss.split(X_resampled.values, y_resampled):
    print(len(train_index))
    print(len(test_index))

    x_train = X_resampled.values[train_index]
    x_val = X_resampled.values[test_index]

    y_train = y_resampled[train_index]
    y_val = y_resampled[test_index]
</code></pre>
<pre><code class="lang-python"><span class="hljs-comment"># &#x5206;&#x5272;&#x6570;&#x636E;&#x56FE;&#x5F62;&#x53EF;&#x89C6;&#x5316;</span>
<span class="hljs-keyword">import</span> seaborn <span class="hljs-keyword">as</span> sns

sns.countplot(y_val)

plt.show()
</code></pre>
<ul>
<li><strong>2.4 &#x6570;&#x636E;&#x6807;&#x51C6;&#x5316;</strong></li>
</ul>
<pre><code class="lang-python"><span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> StandardScaler

scaler = StandardScaler()
scaler.fit(x_train)

x_train_scaled = scaler.transform(x_train)
x_val_scaled = scaler.transform(x_val)
</code></pre>
<ul>
<li><strong>2.5 &#x6570;&#x636E;pca&#x964D;&#x7EF4;</strong></li>
</ul>
<pre><code class="lang-python">print(x_train_scaled.shape)
<span class="hljs-comment"># (13888, 93)</span>

<span class="hljs-keyword">from</span> sklearn.decomposition <span class="hljs-keyword">import</span> PCA

pca = PCA(n_components=<span class="hljs-number">0.9</span>)
x_train_pca = pca.fit_transform(x_train_scaled)
x_val_pca = pca.transform(x_val_scaled)

print(x_train_pca.shape, x_val_pca.shape)
(<span class="hljs-number">13888</span>, <span class="hljs-number">65</span>) (<span class="hljs-number">3473</span>, <span class="hljs-number">65</span>)
</code></pre>
<p>&#x4ECE;&#x4E0A;&#x9762;&#x8F93;&#x51FA;&#x7684;&#x6570;&#x636E;&#x53EF;&#x4EE5;&#x770B;&#x51FA;,&#x53EA;&#x9009;&#x62E9;65&#x4E2A;&#x5143;&#x7D20;,&#x5C31;&#x53EF;&#x4EE5;&#x8868;&#x8FBE;&#x51FA;&#x7279;&#x5F81;&#x4E2D;90%&#x7684;&#x4FE1;&#x606F;</p>
<pre><code class="lang-python"><span class="hljs-comment"># &#x964D;&#x7EF4;&#x6570;&#x636E;&#x53EF;&#x89C6;&#x5316;</span>
plt.plot(np.cumsum(pca.explained_variance_ratio_))

plt.xlabel(<span class="hljs-string">&quot;&#x5143;&#x7D20;&#x6570;&#x91CF;&quot;</span>)
plt.ylabel(<span class="hljs-string">&quot;&#x53EF;&#x8868;&#x8FBE;&#x4FE1;&#x606F;&#x7684;&#x767E;&#x5206;&#x5360;&#x6BD4;&quot;</span>)

plt.show()
</code></pre>
<p><img src="https://tva1.sinaimg.cn/large/0082zybply1gbs7brdvx5j30ow0fo0u8.jpg" alt="image-20200211092529327" style="zoom:50%;"></p>
<hr>
<ul>
<li><strong>3.&#x6A21;&#x578B;&#x8BAD;&#x7EC3;</strong></li>
<li><strong>3.1 &#x57FA;&#x672C;&#x6A21;&#x578B;&#x8BAD;&#x7EC3;</strong></li>
</ul>
<pre><code class="lang-python"><span class="hljs-keyword">from</span> xgboost <span class="hljs-keyword">import</span> XGBClassifier

xgb = XGBClassifier()
xgb.fit(x_train_pca, y_train)

<span class="hljs-comment"># &#x6539;&#x53D8;&#x9884;&#x6D4B;&#x503C;&#x7684;&#x8F93;&#x51FA;&#x6A21;&#x5F0F;,&#x8BA9;&#x8F93;&#x51FA;&#x7ED3;&#x679C;&#x4E3A;&#x767E;&#x5206;&#x5360;&#x6BD4;,&#x964D;&#x4F4E;logloss&#x503C;</span>
y_pre_proba = xgb.predict_proba(x_val_pca)
</code></pre>
<pre><code class="lang-python"><span class="hljs-comment"># logloss&#x8FDB;&#x884C;&#x6A21;&#x578B;&#x8BC4;&#x4F30;</span>
<span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> log_loss
log_loss(y_val, y_pre_proba, eps=<span class="hljs-number">1e-15</span>, normalize=<span class="hljs-keyword">True</span>)

xgb.get_params
</code></pre>
<ul>
<li><strong>3.2 &#x6A21;&#x578B;&#x8C03;&#x4F18;</strong></li>
</ul>
<ul>
<li><p><strong>3.2.1 &#x8C03;&#x4F18;&#x53C2;&#x6570;:</strong></p>
</li>
<li><p><strong>1&#xFF09; n_estimator</strong> </p>
</li>
</ul>
<pre><code class="lang-python">scores_ne = []
n_estimators = [<span class="hljs-number">100</span>,<span class="hljs-number">200</span>,<span class="hljs-number">400</span>,<span class="hljs-number">450</span>,<span class="hljs-number">500</span>,<span class="hljs-number">550</span>,<span class="hljs-number">600</span>,<span class="hljs-number">700</span>]

<span class="hljs-keyword">for</span> nes <span class="hljs-keyword">in</span> n_estimators:
    print(<span class="hljs-string">&quot;n_estimators:&quot;</span>, nes)
    xgb = XGBClassifier(max_depth=<span class="hljs-number">3</span>, 
                        learning_rate=<span class="hljs-number">0.1</span>, 
                        n_estimators=nes, 
                        objective=<span class="hljs-string">&quot;multi:softprob&quot;</span>, 
                        n_jobs=-<span class="hljs-number">1</span>, 
                        nthread=<span class="hljs-number">4</span>, 
                        min_child_weight=<span class="hljs-number">1</span>, 
                        subsample=<span class="hljs-number">1</span>, 
                        colsample_bytree=<span class="hljs-number">1</span>,
                        seed=<span class="hljs-number">42</span>)

    xgb.fit(x_train_pca, y_train)
    y_pre = xgb.predict_proba(x_val_pca)
    score = log_loss(y_val, y_pre)
    scores_ne.append(score)
    print(<span class="hljs-string">&quot;&#x6D4B;&#x8BD5;&#x6570;&#x636E;&#x7684;logloss&#x503C;&#x4E3A;:{}&quot;</span>.format(score))
</code></pre>
<pre><code class="lang-python"><span class="hljs-comment"># &#x6570;&#x636E;&#x53D8;&#x5316;&#x53EF;&#x89C6;&#x5316;</span>
plt.plot(n_estimators, scores_ne, <span class="hljs-string">&quot;o-&quot;</span>)

plt.ylabel(<span class="hljs-string">&quot;log_loss&quot;</span>)
plt.xlabel(<span class="hljs-string">&quot;n_estimators&quot;</span>)
print(<span class="hljs-string">&quot;n_estimators&#x7684;&#x6700;&#x4F18;&#x503C;&#x4E3A;:{}&quot;</span>.format(n_estimators[np.argmin(scores_ne)]))
</code></pre>
<p><img src="https://tva1.sinaimg.cn/large/0082zybply1gbs7fekp7ej30ow0fk0u4.jpg" alt="image-20200211092901936" style="zoom:50%;"></p>
<ul>
<li><strong>2&#xFF09;max_depth</strong></li>
</ul>
<pre><code class="lang-python">scores_md = []
max_depths = [<span class="hljs-number">1</span>,<span class="hljs-number">3</span>,<span class="hljs-number">5</span>,<span class="hljs-number">6</span>,<span class="hljs-number">7</span>]

<span class="hljs-keyword">for</span> md <span class="hljs-keyword">in</span> max_depths:  <span class="hljs-comment"># &#x4FEE;&#x6539;</span>
    xgb = XGBClassifier(max_depth=md, <span class="hljs-comment"># &#x4FEE;&#x6539;</span>
                        learning_rate=<span class="hljs-number">0.1</span>, 
                        n_estimators=n_estimators[np.argmin(scores_ne)],   <span class="hljs-comment"># &#x4FEE;&#x6539; </span>
                        objective=<span class="hljs-string">&quot;multi:softprob&quot;</span>, 
                        n_jobs=-<span class="hljs-number">1</span>, 
                        nthread=<span class="hljs-number">4</span>, 
                        min_child_weight=<span class="hljs-number">1</span>, 
                        subsample=<span class="hljs-number">1</span>, 
                        colsample_bytree=<span class="hljs-number">1</span>,
                        seed=<span class="hljs-number">42</span>)

    xgb.fit(x_train_pca, y_train)
    y_pre = xgb.predict_proba(x_val_pca)
    score = log_loss(y_val, y_pre)
    scores_md.append(score)  <span class="hljs-comment"># &#x4FEE;&#x6539;</span>
    print(<span class="hljs-string">&quot;&#x6D4B;&#x8BD5;&#x6570;&#x636E;&#x7684;logloss&#x503C;&#x4E3A;:{}&quot;</span>.format(log_loss(y_val, y_pre)))
</code></pre>
<pre><code class="lang-python"><span class="hljs-comment"># &#x6570;&#x636E;&#x53D8;&#x5316;&#x53EF;&#x89C6;&#x5316;</span>
plt.plot(max_depths, scores_md, <span class="hljs-string">&quot;o-&quot;</span>)  <span class="hljs-comment"># &#x4FEE;&#x6539;</span>

plt.ylabel(<span class="hljs-string">&quot;log_loss&quot;</span>)
plt.xlabel(<span class="hljs-string">&quot;max_depths&quot;</span>)  <span class="hljs-comment"># &#x4FEE;&#x6539;</span>
print(<span class="hljs-string">&quot;max_depths&#x7684;&#x6700;&#x4F18;&#x503C;&#x4E3A;:{}&quot;</span>.format(max_depths[np.argmin(scores_md)]))  <span class="hljs-comment"># &#x4FEE;&#x6539;</span>
</code></pre>
<ul>
<li><strong>3&#xFF09; min_child_weights,</strong> <ul>
<li>&#x4F9D;&#x636E;&#x4E0A;&#x9762;&#x6A21;&#x5F0F;&#x8FDB;&#x884C;&#x8C03;&#x6574;</li>
</ul>
</li>
<li><strong>4&#xFF09; subsamples,</strong> </li>
<li><strong>5&#xFF09; consample_bytrees,</strong> </li>
<li><p><strong>6&#xFF09; etas</strong></p>
</li>
<li><p><strong>3.2.2 &#x786E;&#x5B9A;&#x6700;&#x540E;&#x6700;&#x4F18;&#x53C2;&#x6570;</strong></p>
</li>
</ul>
<pre><code class="lang-python">xgb = XGBClassifier(learning_rate =<span class="hljs-number">0.1</span>, 
                    n_estimators=<span class="hljs-number">550</span>, 
                    max_depth=<span class="hljs-number">3</span>, 
                    min_child_weight=<span class="hljs-number">3</span>, 
                    subsample=<span class="hljs-number">0.7</span>, 
                    colsample_bytree=<span class="hljs-number">0.7</span>, 
                    nthread=<span class="hljs-number">4</span>, 
                    seed=<span class="hljs-number">42</span>, 
                    objective=<span class="hljs-string">&apos;multi:softprob&apos;</span>)
xgb.fit(x_train_scaled, y_train)

y_pre = xgb.predict_proba(x_val_scaled)

print(<span class="hljs-string">&quot;&#x6D4B;&#x8BD5;&#x6570;&#x636E;&#x7684;logloss&#x503C;&#x4E3A; : {}&quot;</span>.format(log_loss(y_val, y_pre, eps=<span class="hljs-number">1e-15</span>, normalize=<span class="hljs-keyword">True</span>)))
</code></pre>

                    
                    </section>
                
                
                </div>
            </div>
        </div>

        
        <a href="../05-集成学习进阶/section3.html" class="navigation navigation-prev " aria-label="Previous page: XGBoost案例介绍"><i class="fa fa-angle-left"></i></a>
        
        
        <a href="../05-集成学习进阶/section5.html" class="navigation navigation-next " aria-label="Next page: LightGBM"><i class="fa fa-angle-right"></i></a>
        
    </div>
</div>

        
<script src="../gitbook/app.js"></script>

    
    <script src="../gitbook/plugins/gitbook-plugin-code/plugin.js"></script>
    

    
    <script src="../gitbook/plugins/gitbook-plugin-splitter/splitter.js"></script>
    

    
    <script src="../gitbook/plugins/gitbook-plugin-expandable-chapters/expandable-chapters.js"></script>
    

    
    <script src="../gitbook/plugins/gitbook-plugin-fontsettings/buttons.js"></script>
    

<script>
require(["gitbook"], function(gitbook) {
    var config = {"code":{"copyButtons":true},"chart":{"type":"c3"},"splitter":{},"expandable-chapters":{},"graph":{},"katex":{},"highlight":{},"fontsettings":{"theme":"white","family":"sans","size":2}};
    gitbook.start(config);
});
</script>

        
    </body>
    
</html>
