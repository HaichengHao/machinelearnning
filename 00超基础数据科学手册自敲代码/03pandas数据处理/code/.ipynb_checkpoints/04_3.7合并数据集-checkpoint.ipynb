{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d57bd97-7043-4b31-85bd-8b77d5eb67b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       "    *{\n",
       "        # background-color:#E3EDCD;\n",
       "        # background-color:black;\n",
       "        # color:white;\n",
       "        \n",
       "    }\n",
       "    h1{\n",
       "        color:#1976d2;\n",
       "    }\n",
       "    h2{\n",
       "        color:#f57c00;\n",
       "    }\n",
       "    h3{\n",
       "        color:#ba37ff;\n",
       "    }\n",
       "    h4{\n",
       "        color:green;\n",
       "    }\n",
       "    table{\n",
       "        border:1px solid black !important;\n",
       "        border-collapse:collapse !important;\n",
       "    }\n",
       "    th{\n",
       "        background-color:blueviolet !important;\n",
       "        text-align:center;\n",
       "        color:white;\n",
       "    }\n",
       "    th,td{\n",
       "        border:0.1px solid black !important;\n",
       "        transition:0.2s all liner;\n",
       "        \n",
       "    }\n",
       "    td:hover{\n",
       "        transform:scale(1.1);\n",
       "        background-color:orange;\n",
       "        color:blueviolet;\n",
       "    }\n",
       "    .raw{\n",
       "        white-space:pre;\n",
       "        color:green;\n",
       "    }\n",
       "    #imp{\n",
       "        color:red;\n",
       "    }\n",
       "    #ct{\n",
       "        text-align:center;\n",
       "    }\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<style type='text/css'>\n",
    "    *{\n",
    "        # background-color:#E3EDCD;\n",
    "        # background-color:black;\n",
    "        # color:white;\n",
    "        \n",
    "    }\n",
    "    h1{\n",
    "        color:#1976d2;\n",
    "    }\n",
    "    h2{\n",
    "        color:#f57c00;\n",
    "    }\n",
    "    h3{\n",
    "        color:#ba37ff;\n",
    "    }\n",
    "    h4{\n",
    "        color:green;\n",
    "    }\n",
    "    table{\n",
    "        border:1px solid black !important;\n",
    "        border-collapse:collapse !important;\n",
    "    }\n",
    "    th{\n",
    "        background-color:blueviolet !important;\n",
    "        text-align:center;\n",
    "        color:white;\n",
    "    }\n",
    "    th,td{\n",
    "        border:0.1px solid black !important;\n",
    "        transition:0.2s all liner;\n",
    "        \n",
    "    }\n",
    "    td:hover{\n",
    "        transform:scale(1.1);\n",
    "        background-color:orange;\n",
    "        color:blueviolet;\n",
    "    }\n",
    "    .raw{\n",
    "        white-space:pre;\n",
    "        color:green;\n",
    "    }\n",
    "    #imp{\n",
    "        color:red;\n",
    "    }\n",
    "    #ct{\n",
    "        text-align:center;\n",
    "    }\n",
    "    }\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88ad5b7-2005-47e8-a939-b85d15229aa5",
   "metadata": {},
   "source": [
    "## 3.7 合并数据集：Concat与Append操作"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9aca3cf-7108-49c0-9e24-1b6f9de460ef",
   "metadata": {},
   "source": [
    "将不同的数据源进行合并是数据科学中最有趣的事情之一，这既包括将\n",
    "两个不同的数据集非常简单地拼接在一起，也包括用数据库那样的连接\n",
    "（join）与合并（merge）操作处理有重叠字段的数据集。Series 与\n",
    "DataFrame 都具备这类操作，Pandas 的函数与方法让数据合并变得快\n",
    "速简单。    \n",
    "先来用 pd.concat 函数演示一个 Series 与 DataFrame 的简单合并操\n",
    "作。之后，我们将介绍 Pandas 中更复杂的 merge 和 join 内存数据合\n",
    "并操作。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edd5314-faba-43d0-bcfe-c18c1ec1915e",
   "metadata": {},
   "source": [
    "首先导入 Pandas 和 NumPy："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "981cf47f-ab50-424d-a458-2b444103675e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3375b8ed-e6fa-416b-a8ed-ccb049b8b5ef",
   "metadata": {},
   "source": [
    "简单起见，定义一个能够创建 DataFrame 某种形式的函数，后面将会\n",
    "用到：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a134d229-8a20-43a8-a15d-0fbff74fc940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0</td>\n",
       "      <td>B0</td>\n",
       "      <td>C0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A1</td>\n",
       "      <td>B1</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A2</td>\n",
       "      <td>B2</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    A   B   C\n",
       "0  A0  B0  C0\n",
       "1  A1  B1  C1\n",
       "2  A2  B2  C2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_df(cols,ind):\n",
    "    \"\"\"一个简单的DataFrame\"\"\"\n",
    "    data={c:[str(c)+str(i) for i in ind]\n",
    "         for c in cols}\n",
    "    return pd.DataFrame(data,ind)\n",
    "# DataFrame示例\n",
    "make_df('ABC',range(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809811cc-46c5-4901-99d9-68337597621a",
   "metadata": {},
   "source": [
    "### 3.7.1 知识回顾：NumPy数组的合并"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3490375a-c780-4247-93df-56c6426057aa",
   "metadata": {},
   "source": [
    "合并 Series 与 DataFrame 与合并 NumPy 数组基本相同，后者通过\n",
    "2.2 节中介绍的 np.concatenate 函数即可完成。你可以用这个函数将\n",
    "两个或两个以上的数组合并成一个数组。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e833901-d3b0-440f-baad-b31740daf8ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [1, 2, 3]\n",
    "y = [4, 5, 6]\n",
    "z = [7, 8, 9]\n",
    "np.concatenate([x, y, z])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f747c520-599f-42c0-9082-cc06948a6923",
   "metadata": {},
   "source": [
    "第一个参数是需要合并的数组列表或元组。还有一个 axis 参数可以设\n",
    "置合并的坐标轴方向：\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2f6e81-5148-46a9-b42d-72283b5ef1ee",
   "metadata": {},
   "source": [
    "<p class='raw'>\n",
    "如果axis=1为按照列拼,即增加列\n",
    "如果axis=0为按照行拼,即增加行\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1b12cd7-0697-4c48-a435-0369fd6e9b32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 1, 2],\n",
       "       [3, 4, 3, 4]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [[1, 2],\n",
    "[3, 4]]\n",
    "np.concatenate([x, x], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc886882-5077-415a-8d37-29b8b556a0b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mCall signature:\u001b[0m  \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mType:\u001b[0m            _ArrayFunctionDispatcher\n",
       "\u001b[1;31mString form:\u001b[0m     <built-in function concatenate>\n",
       "\u001b[1;31mDocstring:\u001b[0m      \n",
       "concatenate(\n",
       "    (a1, a2, ...), \n",
       "    axis=0, \n",
       "    out=None, \n",
       "    dtype=None, \n",
       "    casting=\"same_kind\"\n",
       ")\n",
       "\n",
       "Join a sequence of arrays along an existing axis.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "a1, a2, ... : sequence of array_like\n",
       "    The arrays must have the same shape, except in the dimension\n",
       "    corresponding to `axis` (the first, by default).\n",
       "axis : int, optional\n",
       "    The axis along which the arrays will be joined.  If axis is None,\n",
       "    arrays are flattened before use.  Default is 0.\n",
       "out : ndarray, optional\n",
       "    If provided, the destination to place the result. The shape must be\n",
       "    correct, matching that of what concatenate would have returned if no\n",
       "    out argument were specified.\n",
       "dtype : str or dtype\n",
       "    If provided, the destination array will have this dtype. Cannot be\n",
       "    provided together with `out`.\n",
       "\n",
       "    .. versionadded:: 1.20.0\n",
       "\n",
       "casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}, optional\n",
       "    Controls what kind of data casting may occur. Defaults to 'same_kind'.\n",
       "    For a description of the options, please see :term:`casting`.\n",
       "    \n",
       "    .. versionadded:: 1.20.0\n",
       "\n",
       "Returns\n",
       "-------\n",
       "res : ndarray\n",
       "    The concatenated array.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "ma.concatenate : Concatenate function that preserves input masks.\n",
       "array_split : Split an array into multiple sub-arrays of equal or\n",
       "              near-equal size.\n",
       "split : Split array into a list of multiple sub-arrays of equal size.\n",
       "hsplit : Split array into multiple sub-arrays horizontally (column wise).\n",
       "vsplit : Split array into multiple sub-arrays vertically (row wise).\n",
       "dsplit : Split array into multiple sub-arrays along the 3rd axis (depth).\n",
       "stack : Stack a sequence of arrays along a new axis.\n",
       "block : Assemble arrays from blocks.\n",
       "hstack : Stack arrays in sequence horizontally (column wise).\n",
       "vstack : Stack arrays in sequence vertically (row wise).\n",
       "dstack : Stack arrays in sequence depth wise (along third dimension).\n",
       "column_stack : Stack 1-D arrays as columns into a 2-D array.\n",
       "\n",
       "Notes\n",
       "-----\n",
       "When one or more of the arrays to be concatenated is a MaskedArray,\n",
       "this function will return a MaskedArray object instead of an ndarray,\n",
       "but the input masks are *not* preserved. In cases where a MaskedArray\n",
       "is expected as input, use the ma.concatenate function from the masked\n",
       "array module instead.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> a = np.array([[1, 2], [3, 4]])\n",
       ">>> b = np.array([[5, 6]])\n",
       ">>> np.concatenate((a, b), axis=0)\n",
       "array([[1, 2],\n",
       "       [3, 4],\n",
       "       [5, 6]])\n",
       ">>> np.concatenate((a, b.T), axis=1)\n",
       "array([[1, 2, 5],\n",
       "       [3, 4, 6]])\n",
       ">>> np.concatenate((a, b), axis=None)\n",
       "array([1, 2, 3, 4, 5, 6])\n",
       "\n",
       "This function will not preserve masking of MaskedArray inputs.\n",
       "\n",
       ">>> a = np.ma.arange(3)\n",
       ">>> a[1] = np.ma.masked\n",
       ">>> b = np.arange(2, 5)\n",
       ">>> a\n",
       "masked_array(data=[0, --, 2],\n",
       "             mask=[False,  True, False],\n",
       "       fill_value=999999)\n",
       ">>> b\n",
       "array([2, 3, 4])\n",
       ">>> np.concatenate([a, b])\n",
       "masked_array(data=[0, 1, 2, 2, 3, 4],\n",
       "             mask=False,\n",
       "       fill_value=999999)\n",
       ">>> np.ma.concatenate([a, b])\n",
       "masked_array(data=[0, --, 2, 2, 3, 4],\n",
       "             mask=[False,  True, False, False, False, False],\n",
       "       fill_value=999999)\n",
       "\u001b[1;31mClass docstring:\u001b[0m\n",
       "Class to wrap functions with checks for __array_function__ overrides.\n",
       "\n",
       "All arguments are required, and can only be passed by position.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "dispatcher : function or None\n",
       "    The dispatcher function that returns a single sequence-like object\n",
       "    of all arguments relevant.  It must have the same signature (except\n",
       "    the default values) as the actual implementation.\n",
       "    If ``None``, this is a ``like=`` dispatcher and the\n",
       "    ``_ArrayFunctionDispatcher`` must be called with ``like`` as the\n",
       "    first (additional and positional) argument.\n",
       "implementation : function\n",
       "    Function that implements the operation on NumPy arrays without\n",
       "    overrides.  Arguments passed calling the ``_ArrayFunctionDispatcher``\n",
       "    will be forwarded to this (and the ``dispatcher``) as if using\n",
       "    ``*args, **kwargs``.\n",
       "\n",
       "Attributes\n",
       "----------\n",
       "_implementation : function\n",
       "    The original implementation passed in."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.concatenate?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebec566a-fd7c-46b2-9ab2-0b7e7b825a3d",
   "metadata": {},
   "source": [
    "### 3.7.2 通过pd.concat实现简易合并"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162f87db-f1ac-423b-bc59-c30c6e8986b0",
   "metadata": {},
   "source": [
    "Pandas 有一个 pd.concat() 函数与 np.concatenate 语法类似，     \n",
    "但是配置参数更多，功能也更强大："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a71fccd-546b-4452-b41a-bb5892845e04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m\n",
       "\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mobjs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'Iterable[Series | DataFrame] | Mapping[HashableT, Series | DataFrame]'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'Axis'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mjoin\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'str'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'outer'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mignore_index\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mkeys\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'Iterable[Hashable] | None'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mlevels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mnames\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'list[HashableT] | None'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mverify_integrity\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0msort\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool | None'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m'DataFrame | Series'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Concatenate pandas objects along a particular axis.\n",
       "\n",
       "Allows optional set logic along the other axes.\n",
       "\n",
       "Can also add a layer of hierarchical indexing on the concatenation axis,\n",
       "which may be useful if the labels are the same (or overlapping) on\n",
       "the passed axis number.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "objs : a sequence or mapping of Series or DataFrame objects\n",
       "    If a mapping is passed, the sorted keys will be used as the `keys`\n",
       "    argument, unless it is passed, in which case the values will be\n",
       "    selected (see below). Any None objects will be dropped silently unless\n",
       "    they are all None in which case a ValueError will be raised.\n",
       "axis : {0/'index', 1/'columns'}, default 0\n",
       "    The axis to concatenate along.\n",
       "join : {'inner', 'outer'}, default 'outer'\n",
       "    How to handle indexes on other axis (or axes).\n",
       "ignore_index : bool, default False\n",
       "    If True, do not use the index values along the concatenation axis. The\n",
       "    resulting axis will be labeled 0, ..., n - 1. This is useful if you are\n",
       "    concatenating objects where the concatenation axis does not have\n",
       "    meaningful indexing information. Note the index values on the other\n",
       "    axes are still respected in the join.\n",
       "keys : sequence, default None\n",
       "    If multiple levels passed, should contain tuples. Construct\n",
       "    hierarchical index using the passed keys as the outermost level.\n",
       "levels : list of sequences, default None\n",
       "    Specific levels (unique values) to use for constructing a\n",
       "    MultiIndex. Otherwise they will be inferred from the keys.\n",
       "names : list, default None\n",
       "    Names for the levels in the resulting hierarchical index.\n",
       "verify_integrity : bool, default False\n",
       "    Check whether the new concatenated axis contains duplicates. This can\n",
       "    be very expensive relative to the actual data concatenation.\n",
       "sort : bool, default False\n",
       "    Sort non-concatenation axis if it is not already aligned. One exception to\n",
       "    this is when the non-concatentation axis is a DatetimeIndex and join='outer'\n",
       "    and the axis is not already aligned. In that case, the non-concatenation\n",
       "    axis is always sorted lexicographically.\n",
       "copy : bool, default True\n",
       "    If False, do not copy data unnecessarily.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "object, type of objs\n",
       "    When concatenating all ``Series`` along the index (axis=0), a\n",
       "    ``Series`` is returned. When ``objs`` contains at least one\n",
       "    ``DataFrame``, a ``DataFrame`` is returned. When concatenating along\n",
       "    the columns (axis=1), a ``DataFrame`` is returned.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "DataFrame.join : Join DataFrames using indexes.\n",
       "DataFrame.merge : Merge DataFrames by indexes or columns.\n",
       "\n",
       "Notes\n",
       "-----\n",
       "The keys, levels, and names arguments are all optional.\n",
       "\n",
       "A walkthrough of how this method fits in with other tools for combining\n",
       "pandas objects can be found `here\n",
       "<https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html>`__.\n",
       "\n",
       "It is not recommended to build DataFrames by adding single rows in a\n",
       "for loop. Build a list of rows and make a DataFrame in a single concat.\n",
       "\n",
       "Examples\n",
       "--------\n",
       "Combine two ``Series``.\n",
       "\n",
       ">>> s1 = pd.Series(['a', 'b'])\n",
       ">>> s2 = pd.Series(['c', 'd'])\n",
       ">>> pd.concat([s1, s2])\n",
       "0    a\n",
       "1    b\n",
       "0    c\n",
       "1    d\n",
       "dtype: object\n",
       "\n",
       "Clear the existing index and reset it in the result\n",
       "by setting the ``ignore_index`` option to ``True``.\n",
       "\n",
       ">>> pd.concat([s1, s2], ignore_index=True)\n",
       "0    a\n",
       "1    b\n",
       "2    c\n",
       "3    d\n",
       "dtype: object\n",
       "\n",
       "Add a hierarchical index at the outermost level of\n",
       "the data with the ``keys`` option.\n",
       "\n",
       ">>> pd.concat([s1, s2], keys=['s1', 's2'])\n",
       "s1  0    a\n",
       "    1    b\n",
       "s2  0    c\n",
       "    1    d\n",
       "dtype: object\n",
       "\n",
       "Label the index keys you create with the ``names`` option.\n",
       "\n",
       ">>> pd.concat([s1, s2], keys=['s1', 's2'],\n",
       "...           names=['Series name', 'Row ID'])\n",
       "Series name  Row ID\n",
       "s1           0         a\n",
       "             1         b\n",
       "s2           0         c\n",
       "             1         d\n",
       "dtype: object\n",
       "\n",
       "Combine two ``DataFrame`` objects with identical columns.\n",
       "\n",
       ">>> df1 = pd.DataFrame([['a', 1], ['b', 2]],\n",
       "...                    columns=['letter', 'number'])\n",
       ">>> df1\n",
       "  letter  number\n",
       "0      a       1\n",
       "1      b       2\n",
       ">>> df2 = pd.DataFrame([['c', 3], ['d', 4]],\n",
       "...                    columns=['letter', 'number'])\n",
       ">>> df2\n",
       "  letter  number\n",
       "0      c       3\n",
       "1      d       4\n",
       ">>> pd.concat([df1, df2])\n",
       "  letter  number\n",
       "0      a       1\n",
       "1      b       2\n",
       "0      c       3\n",
       "1      d       4\n",
       "\n",
       "Combine ``DataFrame`` objects with overlapping columns\n",
       "and return everything. Columns outside the intersection will\n",
       "be filled with ``NaN`` values.\n",
       "\n",
       ">>> df3 = pd.DataFrame([['c', 3, 'cat'], ['d', 4, 'dog']],\n",
       "...                    columns=['letter', 'number', 'animal'])\n",
       ">>> df3\n",
       "  letter  number animal\n",
       "0      c       3    cat\n",
       "1      d       4    dog\n",
       ">>> pd.concat([df1, df3], sort=False)\n",
       "  letter  number animal\n",
       "0      a       1    NaN\n",
       "1      b       2    NaN\n",
       "0      c       3    cat\n",
       "1      d       4    dog\n",
       "\n",
       "Combine ``DataFrame`` objects with overlapping columns\n",
       "and return only those that are shared by passing ``inner`` to\n",
       "the ``join`` keyword argument.\n",
       "\n",
       ">>> pd.concat([df1, df3], join=\"inner\")\n",
       "  letter  number\n",
       "0      a       1\n",
       "1      b       2\n",
       "0      c       3\n",
       "1      d       4\n",
       "\n",
       "Combine ``DataFrame`` objects horizontally along the x axis by\n",
       "passing in ``axis=1``.\n",
       "\n",
       ">>> df4 = pd.DataFrame([['bird', 'polly'], ['monkey', 'george']],\n",
       "...                    columns=['animal', 'name'])\n",
       ">>> pd.concat([df1, df4], axis=1)\n",
       "  letter  number  animal    name\n",
       "0      a       1    bird   polly\n",
       "1      b       2  monkey  george\n",
       "\n",
       "Prevent the result from including duplicate index values with the\n",
       "``verify_integrity`` option.\n",
       "\n",
       ">>> df5 = pd.DataFrame([1], index=['a'])\n",
       ">>> df5\n",
       "   0\n",
       "a  1\n",
       ">>> df6 = pd.DataFrame([2], index=['a'])\n",
       ">>> df6\n",
       "   0\n",
       "a  2\n",
       ">>> pd.concat([df5, df6], verify_integrity=True)\n",
       "Traceback (most recent call last):\n",
       "    ...\n",
       "ValueError: Indexes have overlapping values: ['a']\n",
       "\n",
       "Append a single row to the end of a ``DataFrame`` object.\n",
       "\n",
       ">>> df7 = pd.DataFrame({'a': 1, 'b': 2}, index=[0])\n",
       ">>> df7\n",
       "    a   b\n",
       "0   1   2\n",
       ">>> new_row = pd.Series({'a': 3, 'b': 4})\n",
       ">>> new_row\n",
       "a    3\n",
       "b    4\n",
       "dtype: int64\n",
       ">>> pd.concat([df7, new_row.to_frame().T], ignore_index=True)\n",
       "    a   b\n",
       "0   1   2\n",
       "1   3   4\n",
       "\u001b[1;31mFile:\u001b[0m      d:\\virtualenvs\\ai\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\n",
       "\u001b[1;31mType:\u001b[0m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.concat?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b19892c-3f31-450c-9fe7-75b9e9ef4eeb",
   "metadata": {},
   "source": [
    "pd.concat() 可以简单地合并一维的 Series 或 DataFrame 对象，与\n",
    "np.concatenate() 合并数组一样："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3571537-54a5-480b-8702-1e9b3f77b691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    A\n",
       "2    B\n",
       "3    C\n",
       "4    D\n",
       "5    E\n",
       "6    F\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser1 = pd.Series(['A', 'B', 'C'], index=[1, 2, 3])\n",
    "ser2 = pd.Series(['D', 'E', 'F'], index=[4, 5, 6])\n",
    "pd.concat([ser1, ser2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcdc332-51a8-4d42-ab1d-0480eda51ef6",
   "metadata": {},
   "source": [
    "它也可以用来合并高维数据，例如下面的 DataFrame："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88abf880-5cc3-4409-94a2-f17178c57d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B\n",
      "1  A1  B1\n",
      "2  A2  B2\n",
      "    A   B\n",
      "3  A3  B3\n",
      "4  A4  B4\n",
      "    A   B\n",
      "1  A1  B1\n",
      "2  A2  B2\n",
      "3  A3  B3\n",
      "4  A4  B4\n"
     ]
    }
   ],
   "source": [
    "df1 = make_df('AB', [1, 2])\n",
    "df2 = make_df('AB', [3, 4])\n",
    "print(df1); print(df2); print(pd.concat([df1, df2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196726de-28d5-4af6-b142-4c5ccea0fa5f",
   "metadata": {},
   "source": [
    "默认情况下，DataFrame 的合并都是逐行进行的（默认设置是\n",
    "axis=0）。与 np.concatenate() 一样，pd.concat 也可以设置合并\n",
    "坐标轴，例如下面的示例：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c28ea4d-032c-4c61-94a6-aed6d3b5c6ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B\n",
      "0  A0  B0\n",
      "1  A1  B1\n",
      "    C   D\n",
      "0  C0  D0\n",
      "1  C1  D1\n",
      "    A   B   C   D\n",
      "0  A0  B0  C0  D0\n",
      "1  A1  B1  C1  D1\n"
     ]
    }
   ],
   "source": [
    "df3 = make_df('AB', [0, 1])\n",
    "df4 = make_df('CD', [0, 1])\n",
    "print(df3); print(df4); print(pd.concat([df3, df4], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf271b4-f63c-488a-8c68-02ec7bdfa32e",
   "metadata": {},
   "source": [
    "01. 索引重复"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a799494-5f0d-42ba-b003-217a39f398bd",
   "metadata": {},
   "source": [
    "np.concatenate 与 pd.concat 最主要的差异之一就是 Pandas 在\n",
    "合并时会保留索引，即使索引是重复的！例如下面的简单示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf2fed86-8c33-4a63-9d9e-a8b0bbd3a0d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B\n",
      "0  A0  B0\n",
      "1  A1  B1\n",
      "    A   B\n",
      "0  A2  B2\n",
      "1  A3  B3\n",
      "    A   B\n",
      "0  A0  B0\n",
      "1  A1  B1\n",
      "0  A2  B2\n",
      "1  A3  B3\n"
     ]
    }
   ],
   "source": [
    "x = make_df('AB', [0, 1])\n",
    "y = make_df('AB', [2, 3])\n",
    "y.index = x.index # 复制索引\n",
    "print(x); print(y); print(pd.concat([x, y]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abff2da-d8d9-4cdf-9d51-2cd50e5b6403",
   "metadata": {},
   "source": [
    "你会发现结果中的索引是重复的。虽然 DataFrame 允许这么做，\n",
    "但结果并不是我们想要的。pd.concat() 提供了一些解决这个问\n",
    "题的方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a55408f-dcc7-433f-bac2-05849fa54677",
   "metadata": {},
   "source": [
    "(1) 捕捉索引重复的错误。如果你想要检测 pd.concat() 合并的结\n",
    "果中是否出现了重复的索引，可以设置 verify_integrity 参\n",
    "数。将参数设置为 True，合并时若有索引重复就会触发异常。下\n",
    "面的示例可以让我们清晰地捕捉并打印错误信息："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f36c7538-baf3-4911-8203-a9ad5dc4c2ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ValueError: Indexes have overlapping values: Index([0, 1], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    pd.concat([x, y], verify_integrity=True)\n",
    "except ValueError as e:\n",
    "    print(\"ValueError:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3008ed-002d-47ed-806b-cf2e928f83e0",
   "metadata": {},
   "source": [
    "(2) 忽略索引。有时索引无关紧要，那么合并时就可以忽略它们，\n",
    "可以通过设置 ignore_index 参数来实现。如果将参数设置为\n",
    "True，那么合并时将会创建一个新的整数索引。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d797aa1c-6f1f-4169-8334-8a64a06a85df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B\n",
      "0  A0  B0\n",
      "1  A1  B1\n",
      "    A   B\n",
      "0  A2  B2\n",
      "1  A3  B3\n",
      "    A   B\n",
      "0  A0  B0\n",
      "1  A1  B1\n",
      "2  A2  B2\n",
      "3  A3  B3\n"
     ]
    }
   ],
   "source": [
    "print(x); print(y); print(pd.concat([x, y], ignore_index=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6911bda6-2a85-4aac-89ea-c3d0f83aeccb",
   "metadata": {},
   "source": [
    "(3) 增加多级索引。另一种处理索引重复的方法是通过 keys 参数\n",
    "为数据源设置多级索引标签，这样结果数据就会带上多级索引："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be934d0f-1be1-4df2-a84c-ffb33fb7437a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B\n",
      "0  A0  B0\n",
      "1  A1  B1\n",
      "    A   B\n",
      "0  A2  B2\n",
      "1  A3  B3\n",
      "      A   B\n",
      "x 0  A0  B0\n",
      "  1  A1  B1\n",
      "y 0  A2  B2\n",
      "  1  A3  B3\n"
     ]
    }
   ],
   "source": [
    "print(x); print(y); print(pd.concat([x, y], keys=['x', 'y']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d15c421-61b6-4d4a-93eb-ad1e9a8d39c2",
   "metadata": {},
   "source": [
    "示例合并后的结果是多级索引的 DataFrame，可以用 3.6 节介绍的\n",
    "方法将它转换成我们需要的形式。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e670f1aa-c1c9-4c16-9d56-a515173ec9fa",
   "metadata": {},
   "source": [
    "02. 类似join的合并"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbaf157-2b1c-4f1f-bd0e-81047da3eb72",
   "metadata": {},
   "source": [
    "前面介绍的简单示例都有一个共同特点，那就是合并的 DataFrame  \n",
    "都是同样的列名。而在实际工作中，需要合并的数据往往带有不同  \n",
    "的列名，而 pd.concat 提供了一些选项来解决这类合并问题。看  \n",
    "下面两个 DataFrame，它们的列名部分相同，却又不完全相同："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b0521fd-2778-4485-b17e-307c79df0d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C\n",
      "1  A1  B1  C1\n",
      "2  A2  B2  C2\n",
      "    B   C   D\n",
      "3  B3  C3  D3\n",
      "4  B4  C4  D4\n",
      "     A   B   C    D\n",
      "1   A1  B1  C1  NaN\n",
      "2   A2  B2  C2  NaN\n",
      "3  NaN  B3  C3   D3\n",
      "4  NaN  B4  C4   D4\n"
     ]
    }
   ],
   "source": [
    "df5 = make_df('ABC', [1, 2])\n",
    "df6 = make_df('BCD', [3, 4])\n",
    "print(df5)\n",
    "print(df6)\n",
    "print(pd.concat([df5,df6]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24624fdb-9e1e-42d8-98a5-2b85e251bb97",
   "metadata": {},
   "source": [
    "默认情况下，某个位置上缺失的数据会用 NaN 表示。如果不想这  \n",
    "样，可以用 join 和 join_axes 参数设置合并方式。默认的合并方  \n",
    "式是对所有输入列进行并集合并（join='outer'），当然也可以  \n",
    "用 <span id='imp'>join='inner' </span>实现对输入列的交集合并：  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "495a289c-0d04-4fb7-912c-078144be1ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C\n",
      "1  A1  B1  C1\n",
      "2  A2  B2  C2\n",
      "    B   C   D\n",
      "3  B3  C3  D3\n",
      "4  B4  C4  D4\n",
      "    B   C\n",
      "1  B1  C1\n",
      "2  B2  C2\n",
      "3  B3  C3\n",
      "4  B4  C4\n"
     ]
    }
   ],
   "source": [
    "print(df5); print(df6);\n",
    "print(pd.concat([df5, df6], join='inner'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df842f25-287a-4ba9-9662-f7a95c821a84",
   "metadata": {},
   "source": [
    "另一种合并方式是直接确定结果使用的列名，设置 join_axes 参\n",
    "数，里面是索引对象构成的列表（是列表的列表）。如下面示例所\n",
    "示，将结果的列名设置为第一个输入的列名：  \n",
    "<p id='imp'>在较新的版本中，join_axes 参数已被废弃，可以使用 reindex 方法替代。<br>\n",
    "以下是解决该问题的方法：\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae024458-436f-405f-a025-a06f77464c2d",
   "metadata": {},
   "source": [
    "```python\n",
    "# 替换前\n",
    "result = pd.concat([df1, df2], join_axes=[df1.columns])\n",
    "\n",
    "# 替换后\n",
    "result = pd.concat([df1, df2]).reindex(columns=df1.columns)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cf641793-b112-4194-9e65-18f629aba5c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C\n",
      "1  A1  B1  C1\n",
      "2  A2  B2  C2\n",
      "    B   C   D\n",
      "3  B3  C3  D3\n",
      "4  B4  C4  D4\n",
      "     A   B   C\n",
      "1   A1  B1  C1\n",
      "2   A2  B2  C2\n",
      "3  NaN  B3  C3\n",
      "4  NaN  B4  C4\n"
     ]
    }
   ],
   "source": [
    "print(df5)\n",
    "print(df6)\n",
    "print(pd.concat([df5,df6]).reindex(columns=df5.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a990f6a9-aa06-45b6-860c-b5793df0ffd6",
   "metadata": {},
   "source": [
    "pd.concat 的合并功能可以满足你在合并两个数据集时的许多需\n",
    "求，操作时请记住这一点。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7467b2ed-fb3d-45be-bd4f-63331f751e6a",
   "metadata": {},
   "source": [
    "03. append()方法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e342d9-67fa-4263-b942-0ded1bb6ade6",
   "metadata": {},
   "source": [
    "因为直接进行数组合并的需求非常普遍，所以 Series 和\n",
    "DataFrame 对象都支持 append 方法，让你通过最少的代码实现合\n",
    "并功能。例如，你可以使用 df1.append(df2)，效果与\n",
    "pd.concat([df1, df2]) 一样：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4d327e70-91a0-495e-ab2b-74b44987dfd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B\n",
      "1  A1  B1\n",
      "2  A2  B2\n",
      "    A   B\n",
      "3  A3  B3\n",
      "4  A4  B4\n",
      "    A   B\n",
      "1  A1  B1\n",
      "2  A2  B2\n",
      "3  A3  B3\n",
      "4  A4  B4\n"
     ]
    }
   ],
   "source": [
    "print(df1)\n",
    "print(df2)\n",
    "print(df1._append(df2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc00b40-e7ac-4ece-8710-4950f6036d9d",
   "metadata": {},
   "source": [
    "<span id='imp'>注意,上面在写代码时,append已经被废弃,取而代之的是私有方法<br>\n",
    "._append()不建议使用,还是老老实实使用.concat()就行</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec17556-d7ef-4b7d-a7e7-703505ac7486",
   "metadata": {},
   "source": [
    "需要注意的是，与 Python 列表中的 append() 和 extend() 方法不\n",
    "同，Pandas 的 append() 不直接更新原有对象的值，而是为合并后\n",
    "的数据创建一个新对象。因此，它不能被称之为一个非常高效的解\n",
    "决方案，因为每次合并都需要重新创建索引和数据缓存。总之，如\n",
    "果你需要进行多个 append 操作，还是建议先创建一个 DataFrame\n",
    "列表，然后用 concat() 函数一次性解决所有合并任务。\n",
    "下一节将介绍另一种功能强大的数据组合方法——类似数据库的数\n",
    "据合并，在 pd.merge 里实现。关于 concat() 与 append() 的更\n",
    "多信息，请参考 Pandas 文档中“Merge, Join, and\n",
    "Concatenate”（http://pandas.pydata.org/pandasdocs/stable/merging.html）节"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc9a106-646c-4cd4-a46e-d37e14483c0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
